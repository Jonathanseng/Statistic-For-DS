
In statistics, degrees of freedom (df) is the number of values in the final calculation of a statistic that are free to vary. Estimates of statistical parameters can be based upon different amounts of information or data. The number of independent pieces of information that go into the estimate of a parameter is called the degrees of freedom.

Mathematically, degrees of freedom is the number of dimensions of the domain of a random vector, or essentially the number of "free" components (how many components need to be known before the vector is fully determined).

For example, if you have a sample of 10 people and you want to calculate the mean height, you have 9 degrees of freedom. This is because you know the total height of the 10 people (100 inches), and you know the mean height (60 inches). This leaves 9 degrees of freedom for the individual heights.

Degrees of freedom are important in statistical tests because they affect the distribution of the test statistic. The more degrees of freedom a test has, the more likely it is to be significant.

Here are some examples of degrees of freedom in different statistical tests:

* **t-test:** The degrees of freedom for a t-test are the number of observations minus 2.
* **F-test:** The degrees of freedom for an F-test are the degrees of freedom of the numerator and the degrees of freedom of the denominator.
* **Chi-squared test:** The degrees of freedom for a chi-squared test are the number of rows minus 1, multiplied by the number of columns minus 1.

Degrees of freedom are an important concept in statistics. They help us to understand the distribution of test statistics and to make inferences about populations.
